{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Column|Description|\n",
    "|:------:|:---:|\n",
    "|<code>category</code>| Topic (target variable) |\n",
    "|<code>description</code>| Description |\n",
    "|<code>text_content</code>| Text content |\n",
    "|<code>title</code>| Title |\n",
    "|<code>h1</code>| Content of the <code>h1</code> tag on the page |\n",
    "|<code>h2</code>| Content of the <code>h2</code> tag on the page |\n",
    "|<code>url</code>| Link address|\n",
    "|<code>domain</code>| Website domain |\n",
    "|<code>id</code>| Link ID|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hazm import Normalizer, word_tokenize\n",
    "import string\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>text_content</th>\n",
       "      <th>title</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>کتاب و ادبیات</td>\n",
       "      <td>از شوبنده ها: جستجو معنی \"از شوبنده ها\" در فره...</td>\n",
       "      <td>معنی از شوبنده ها | جدول یاب از شوبنده ها 381</td>\n",
       "      <td>معنی از شوبنده ها | جدول یاب</td>\n",
       "      <td>معنی از شوبنده ها</td>\n",
       "      <td>از شوبنده ها در معادل ابجد</td>\n",
       "      <td>jadvalyab.ir/search?q=%D8%A7%D8%B2+%D8%B4%D9%8...</td>\n",
       "      <td>jadvalyab.ir</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                        description  \\\n",
       "0  کتاب و ادبیات  از شوبنده ها: جستجو معنی \"از شوبنده ها\" در فره...   \n",
       "\n",
       "                                     text_content  \\\n",
       "0   معنی از شوبنده ها | جدول یاب از شوبنده ها 381   \n",
       "\n",
       "                           title                 h1  \\\n",
       "0   معنی از شوبنده ها | جدول یاب  معنی از شوبنده ها   \n",
       "\n",
       "                           h2  \\\n",
       "0  از شوبنده ها در معادل ابجد   \n",
       "\n",
       "                                                 url        domain   id  \n",
       "0  jadvalyab.ir/search?q=%D8%A7%D8%B2+%D8%B4%D9%8...  jadvalyab.ir  158  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/yektanet_train.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "سلامت                  614\n",
       "ورزش                   514\n",
       "حقوق و دولت و سیاست    486\n",
       "هنر و سرگرمی           410\n",
       "موسیقی                 314\n",
       "تکنولوژی و کامپبوتر    287\n",
       "تجارت و اقتصاد         283\n",
       "فیلم و سینما           239\n",
       "خودرو                  237\n",
       "اجتماعی                209\n",
       "سفر و گردشگری          182\n",
       "غذا و نوشیدنی          171\n",
       "مذهبی                  160\n",
       "مسکن                   131\n",
       "خانه و باغبانی         128\n",
       "مد و زیبایی            118\n",
       "کتاب و ادبیات           83\n",
       "تحصیلات                 79\n",
       "اشتغال                  47\n",
       "علم و دانش              34\n",
       "خانواده                 34\n",
       "حیوانات خانگی           29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=['category'])\n",
    "y_train = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "data_resampled, targets_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "کتاب و ادبیات          614\n",
       "تجارت و اقتصاد         614\n",
       "اشتغال                 614\n",
       "خانواده                614\n",
       "علم و دانش             614\n",
       "تحصیلات                614\n",
       "موسیقی                 614\n",
       "خانه و باغبانی         614\n",
       "هنر و سرگرمی           614\n",
       "سفر و گردشگری          614\n",
       "فیلم و سینما           614\n",
       "مذهبی                  614\n",
       "اجتماعی                614\n",
       "مد و زیبایی            614\n",
       "خودرو                  614\n",
       "مسکن                   614\n",
       "حقوق و دولت و سیاست    614\n",
       "غذا و نوشیدنی          614\n",
       "ورزش                   614\n",
       "تکنولوژی و کامپبوتر    614\n",
       "سلامت                  614\n",
       "حیوانات خانگی          614\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_stopwords = set([\n",
    "    \"از\", \"به\", \"در\", \"با\", \"که\", \"را\", \"تا\", \"و\", \"یا\", \"اما\", \"اگر\", \"برای\", \"بر\", \n",
    "    \"این\", \"آن\", \"یک\", \"هر\", \"هم\", \"همه\", \"چند\", \"چنین\", \"دیگر\", \"چون\", \"مثل\", \n",
    "    \"مانند\", \"چرا\", \"زیرا\", \"ولی\", \"آیا\", \"اگرچه\", \"لذا\", \"نیز\", \"باید\", \"می\", \n",
    "    \"باشد\", \"است\", \"بود\", \"هست\", \"شد\", \"شو\", \"باش\", \"کرد\", \"کن\", \"کند\", \"کرده\", \n",
    "    \"شده\", \"می‌شود\", \"خواهد\", \"خواهند\", \"خواهی\", \"خواهیم\", \"توان\", \"تواند\", \n",
    "    \"توانند\", \"توانست\", \"توانسته\", \"بوده\", \"نبود\", \"نباشد\", \"نیست\", \"نیستند\", \n",
    "    \"بودند\", \"باشند\", \"هستند\", \"دارم\", \"داری\", \"دارد\", \"دارند\", \"داریم\", \"داشت\", \n",
    "    \"داشتند\", \"داشته\", \"داشتم\", \"ندارم\", \"ندارد\", \"ندارند\", \"نداریم\", \"نداشت\", \n",
    "    \"نداشتند\", \"نداشته\", \"ای\", \"ایم\", \"اید\", \"اند\", \"ام\", \"ت\", \"ها\", \"های\", \"هایی\", \n",
    "    \"شان\", \"ش\", \"مان\", \"تان\", \"اینها\", \"آنها\", \"چیز\", \"چیزی\", \"چرا\", \"چه\", \"که\", \n",
    "    \"کدام\", \"چگونه\", \"چقدر\", \"چراکه\", \"آنان\", \"او\", \"آن\", \"ایشان\", \"ما\", \"شما\", \n",
    "    \"آنچه\", \"آنجا\", \"اینجا\", \"اینجاست\", \"آنجاست\", \"همان\", \"خود\", \"همه‌اش\", \n",
    "    \"هیچ\", \"هیچ‌کدام\", \"هرگز\", \"هیچگاه\", \"حالا\", \"اکنون\", \"دیروز\", \"امروز\", \n",
    "    \"فردا\", \"شب\", \"روز\", \"بعد\", \"قبل\", \"ساعت\", \"وقت\", \"زمان\", \"چندین\", \"بار\", \n",
    "    \"کم\", \"بیشتر\", \"کمتر\", \"حتی\", \"فقط\", \"تنها\", \"بالا\", \"پایین\", \"روی\", \"زیر\", \n",
    "    \"جلو\", \"پشت\", \"نزدیک\", \"دور\", \"وسط\", \"بیرون\", \"درون\", \"داخل\", \"کنار\", \n",
    "    \"اینجا\", \"آنجا\", \"هیچ‌جا\", \"هرجا\", \"هرکجا\", \"جا\", \"مکان\", \"محل\", \"چپ\", \"راست\", \n",
    "    \"بعدا\", \"سپس\", \"آنگاه\", \"دیگر\", \"چیزهای\", \"یعنی\", \"خب\", \"آره\", \"نه\", \"باشه\", \n",
    "    \"آها\", \"بله\", \"نمیدانم\", \"کسی\", \"دیگری\", \"هیچ‌کسی\", \"چیزها\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "\n",
    "def preprocessor(input):\n",
    "    punc_removed = input.translate(str.maketrans('', '', string.punctuation))\n",
    "    normalized = normalizer.normalize(punc_removed)\n",
    "    tokens = word_tokenize(normalized)\n",
    "    filtered = []\n",
    "    for token in tokens:\n",
    "        token = str(token)\n",
    "        token = token.lower()\n",
    "        if not token in persian_stopwords and not token.isdigit():\n",
    "            filtered.append(token)\n",
    "    output = ' '.join(filtered)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "targets_resampled = encoder.fit_transform(targets_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_resampled['title'], targets_resampled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 16, 15, ..., 13, 10,  1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Courses&Code\\ML_excersice\\env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm = Pipeline([('vect', CountVectorizer(tokenizer=tokenizer, preprocessor=preprocessor,\n",
    "                                         analyzer='word', ngram_range=(1, 2),\n",
    "                                         min_df=5, lowercase=False)),\n",
    "                ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "                ('clf-svm', LinearSVC(loss='hinge', penalty='l2', max_iter=5000))])\n",
    "\n",
    "model = svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1-score: 0.9786719365950901\n",
      "Test F1-score: 0.9207918952208628\n"
     ]
    }
   ],
   "source": [
    "print('Training F1-score:', f1_score(y_train, model.predict(X_train), average='weighted'))\n",
    "print('Test F1-score:', f1_score(y_test, model.predict(X_test), average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Courses&Code\\ML_excersice\\env\\lib\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "e:\\Courses&Code\\ML_excersice\\env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "xgb = Pipeline([('vect', CountVectorizer(tokenizer=tokenizer, preprocessor=preprocessor,\n",
    "                                         analyzer='word', ngram_range=(1, 2),\n",
    "                                         min_df=5, lowercase=False)),\n",
    "                ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "                ('clf-svm', XGBClassifier(  # XGBClassifier for multi-class classification\n",
    "                                objective='multi:softmax',  # Use 'multi:softprob' for probabilities\n",
    "                                num_class=22,  # Number of classes\n",
    "                                eval_metric='mlogloss',  # Metric for multi-class classification\n",
    "                                use_label_encoder=False,  # Disable label encoder\n",
    "                                random_state=42\n",
    "                            ))])\n",
    "\n",
    "model = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1-score: 0.9662009710899965\n",
      "Test F1-score: 0.9120089016281424\n"
     ]
    }
   ],
   "source": [
    "print('Training F1-score:', f1_score(y_train, model.predict(X_train), average='weighted'))\n",
    "print('Test F1-score:', f1_score(y_test, model.predict(X_test), average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
